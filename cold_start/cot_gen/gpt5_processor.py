#!/usr/bin/env python3
"""
GPT-5-mini Real-time API Processor for Visual Task Progress Evaluation

åŠŸèƒ½ç‰¹æ€§ï¼š
1. LIMIT: é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡
2. RESUME: æ–­ç‚¹ç»­ä¼ åŠŸèƒ½ï¼Œå¯ä»¥ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­å¤„ç†
3. å”¯ä¸€æ ‡è¯†: ä½¿ç”¨ "id"_"progress_score" ä½œä¸ºæ ·æœ¬çš„å”¯ä¸€æ ‡è¯†

æˆåŠŸè¾“å‡ºæ ¼å¼ï¼š
{
    "ref": "2",                              # ä»<ref>æ ‡ç­¾æå–çš„å‚è€ƒå¸§ç¼–å·
    "score": "8%",                           # ä»<score>æ ‡ç­¾æå–çš„è¿›åº¦åˆ†æ•°
    "closest_idx": "1",                      # è¾“å…¥æ•°æ®ä¸­çš„æœ€è¿‘ç´¢å¼•
    "ground_truth_score": "8%",              # è¾“å…¥æ•°æ®ä¸­çš„çœŸå®åˆ†æ•°
    "response": "å®Œæ•´çš„GPT-5å“åº”...",        # åŒ…å«æ‰€æœ‰æ ‡ç­¾çš„å®Œæ•´å“åº”
    "meta_data": {                           # å…ƒæ•°æ®ä¿¡æ¯
        "id": "æ ·æœ¬ID",
        "task_goal": "ä»»åŠ¡æè¿°",
        "tokens_used": 2500,
        "model": "gpt-5-mini",
        "timestamp": "2025-01-17T10:30:45",
        "status": "success"
    }
}

é”™è¯¯è¾“å‡ºæ ¼å¼ï¼š
{
    "ref": null,
    "score": null,
    "closest_idx": "1",
    "ground_truth_score": "8%",
    "response": null,
    "meta_data": {
        "id": "æ ·æœ¬ID",
        "task_goal": "ä»»åŠ¡æè¿°",
        "error": "é”™è¯¯ä¿¡æ¯",
        "traceback": "å®Œæ•´å †æ ˆè¿½è¸ª",
        "timestamp": "2025-01-17T10:30:45",
        "status": "error"
    }
}
"""

import json
import os
import sys
import time
import base64
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime
import argparse
from tqdm import tqdm
import traceback
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# å…¨å±€é”ç”¨äºæ–‡ä»¶å†™å…¥
write_lock = threading.Lock()

class VisualProgressProcessor:
    """è§†è§‰è¿›åº¦è¯„ä¼°å¤„ç†å™¨"""
    
    def __init__(self, api_key: str, image_dir: str, model: str = "gpt-5-mini"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            image_dir: å›¾åƒåŸºç¡€ç›®å½•
            model: ä½¿ç”¨çš„æ¨¡å‹
        """
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.image_dir = Path(image_dir)
        
        if not self.image_dir.exists():
            raise ValueError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
    
    def encode_image(self, image_path: Path) -> str:
        """
        å°†å›¾åƒç¼–ç ä¸ºbase64
        
        Args:
            image_path: å›¾åƒè·¯å¾„
        
        Returns:
            base64ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²
        """
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ {image_path}: {str(e)}")
    
    def build_image_content(self, image_path: Path) -> Dict:
        """
        æ„å»ºå›¾åƒæ¶ˆæ¯å†…å®¹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
        
        Returns:
            OpenAI APIæ ¼å¼çš„å›¾åƒå†…å®¹
        """
        base64_image = self.encode_image(image_path)
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}",
                "detail": "high"  # ä½¿ç”¨é«˜è´¨é‡å›¾åƒåˆ†æ
            }
        }
    
    def calculate_progress_scores(self, total_steps: int) -> List[str]:
        """
        æ ¹æ®æ€»æ­¥æ•°è®¡ç®—è¿›åº¦åˆ†æ•°
        
        Args:
            total_steps: æ€»æ­¥æ•°
        
        Returns:
            è¿›åº¦ç™¾åˆ†æ¯”åˆ—è¡¨
        """
        scores = ["0%"]
        if total_steps > 0:
            step_size = 100 / total_steps
            for i in range(1, total_steps + 1):
                scores.append(f"{int(i * step_size)}%")
        return scores
    
    def build_message_content(self, sample: Dict) -> List[Dict]:
        """
        æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†…å®¹
        
        Args:
            sample: JSONLä¸­çš„ä¸€ä¸ªæ ·æœ¬
        
        Returns:
            æ¶ˆæ¯å†…å®¹åˆ—è¡¨
        """
        content = []
        
        # 1. ç³»ç»Ÿæç¤ºè¯çš„ç¬¬ä¸€éƒ¨åˆ†
        system_prompt = (
            "You are an expert AI analyst specializing in visual task-progress evaluations "
            "Your objective is not to estimate from scratch. "
            "Instead, your task is to construct a perfect, human-like chain of thought that "
            "logically explains and justifies a known, ground-truth progress score. "
            "Your entire response must read as if you are deducing the conclusion independently "
            "from visual analysis alone. This is the system prompt for normal inference. "
            "You are a progress estimator specializing in evaluating the progress of an ongoing "
            "task based on visual evidence. The demonstration consists of a sequence of video "
            "frames (images) showing how the task evolves from 0% (start) to 100% (completion). "
            "Your goal is to produce a human-like reasoning chain that logically supports the "
            "given progress score. Here is the demonstration:"
        )
        content.append({"type": "text", "text": system_prompt})
        
        # 2. æ·»åŠ visual_demoä¸­çš„æ‰€æœ‰å›¾ç‰‡
        sample_id = sample['id']
        for demo_image in sample['visual_demo']:
            image_path = self.image_dir / sample_id / demo_image
            if not image_path.exists():
                raise FileNotFoundError(f"æ¼”ç¤ºå›¾åƒä¸å­˜åœ¨: {image_path}")
            content.append(self.build_image_content(image_path))
        
        # 3. æ„å»ºè¿›åº¦è½¬æ¢æ–‡æœ¬
        total_steps = int(sample['total_steps'])
        progress_scores = self.calculate_progress_scores(total_steps)
        
        progress_text = "The progress shifts across all given visual demos is: "
        for i, score in enumerate(progress_scores):
            if i > 0:
                progress_text += " "
            progress_text += f"<image> {score}"
        
        content.append({"type": "text", "text": progress_text})
        
        # 4. æ·»åŠ å½“å‰çŠ¶æ€æç¤º
        content.append({
            "type": "text", 
            "text": "Here is the current state that you need to estimate:"
        })
        
        # 5. æ·»åŠ stage_to_estimateå›¾ç‰‡
        stage_image = sample['stage_to_estimate'][0]  # å‡è®¾åªæœ‰ä¸€å¼ å›¾ç‰‡
        stage_path = self.image_dir / sample_id / stage_image
        if not stage_path.exists():
            raise FileNotFoundError(f"è¯„ä¼°å›¾åƒä¸å­˜åœ¨: {stage_path}")
        content.append(self.build_image_content(stage_path))
        
        # 6. æ·»åŠ å…³é”®è§„åˆ™å’Œground truth
        critical_rule = (
            f"**Critical Rule** The correct final progress score will be provided to you. "
            f"However, you must **never** reveal or imply that you already know the answer. "
            f"Your reasoning must appear as a fully original, independent visual analysis "
            f"derived from the images.\n\n"
            f"**Ground-Truth Progress Result**\n"
            f"Closest Reference Frame: The No. {sample['closest_idx']} demo image is the most relevant frame\n"
            f"Final Progress Score to Justify: {sample['progress_score']}"
        )
        content.append({"type": "text", "text": critical_rule})
        
        # 7. æ·»åŠ ä»»åŠ¡è¯´æ˜å’Œè¾“å‡ºæ ¼å¼
        task_instructions = (
            "\nYour task:\n"
            "1. Analyze the demonstration images to understand how the task visually progresses from start to completion.\n"
            "2. Identify which frame in the provided visual demos is visually most similar to the current state image.\n"
            "3. Compare the current state to that reference frame and determine whether it shows more or less progress.\n"
            "4. Finally, provide a numeric progress estimation between 0% and 100%.\n\n"
            "**Output Format**\n"
            "Your response must strictly follow this format:\n"
            "<ref_think>Your reasoning for choosing the closest demonstration frame as the reference</ref_think>\n"
            "<ref>identify which image is most visually similar to the current state, and output only the number of that image</ref>\n"
            "<score_think>Your reasoning for comparing the current state image with the reference frame(s)</score_think>\n"
            "<score>Your final estimated progress score here</score>"
        )
        content.append({"type": "text", "text": task_instructions})
        
        return content
        
        # 4. æ·»åŠ å½“å‰çŠ¶æ€æç¤º
        content.append({
            "type": "text", 
            "text": "Here is the current state that you need to estimate:"
        })
        
        # 5. æ·»åŠ stage_to_estimateå›¾ç‰‡
        stage_image = sample['stage_to_estimate'][0]  # å‡è®¾åªæœ‰ä¸€å¼ å›¾ç‰‡
        stage_path = self.image_dir / sample_id / stage_image
        if not stage_path.exists():
            raise FileNotFoundError(f"è¯„ä¼°å›¾åƒä¸å­˜åœ¨: {stage_path}")
        content.append(self.build_image_content(stage_path))
        
        # 6. æ·»åŠ å…³é”®è§„åˆ™å’Œground truth
        critical_rule = (
            f"**Critical Rule** The correct final progress score will be provided to you. "
            f"However, you must **never** reveal or imply that you already know the answer. "
            f"Your reasoning must appear as a fully original, independent visual analysis "
            f"derived from the images.\n\n"
            f"**Ground-Truth Progress Result**\n"
            f"Closest Reference Frame: The No. {sample['closest_idx']} demo image is the most relevant frame\n"
            f"Final Progress Score to Justify: {sample['progress_score']}"
        )
        content.append({"type": "text", "text": critical_rule})
        
        # 7. æ·»åŠ ä»»åŠ¡è¯´æ˜å’Œè¾“å‡ºæ ¼å¼
        task_instructions = (
            "\nYour task:\n"
            "1. Analyze the demonstration images to understand how the task visually progresses from start to completion.\n"
            "2. Identify which frame in the provided visual demos is visually most similar to the current state image.\n"
            "3. Compare the current state to that reference frame and determine whether it shows more or less progress.\n"
            "4. Finally, provide a numeric progress estimation between 0% and 100%.\n\n"
            "**Output Format**\n"
            "Your response must strictly follow this format:\n"
            "<ref_think>Your reasoning for choosing the closest demonstration frame as the reference</ref_think>\n"
            "<ref>identify which image is most visually similar to the current state, and output only the number of that image</ref>\n"
            "<score_think>Your reasoning for comparing the current state image with the reference frame(s)</score_think>\n"
            "<score>Your final estimated progress score here</score>"
        )
        content.append({"type": "text", "text": task_instructions})
        
        return content
    
    def get_sample_unique_id(self, sample: Dict) -> str:
        """
        ç”Ÿæˆæ ·æœ¬çš„å”¯ä¸€æ ‡è¯†
        
        Args:
            sample: JSONLä¸­çš„ä¸€ä¸ªæ ·æœ¬
        
        Returns:
            å”¯ä¸€æ ‡è¯†å­—ç¬¦ä¸²: id_progress_score
        """
        sample_id = sample.get('id', 'unknown')
        progress_score = sample.get('progress_score', 'unknown')
        return f"{sample_id}_{progress_score}"
    
    def load_processed_ids(self, output_file: Path) -> set:
        """
        ä»è¾“å‡ºæ–‡ä»¶åŠ è½½å·²å¤„ç†çš„æ ·æœ¬ID
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            å·²å¤„ç†çš„å”¯ä¸€IDé›†åˆ
        """
        processed_ids = set()
        
        if not output_file.exists():
            return processed_ids
        
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        result = json.loads(line.strip())
                        # ä»meta_dataä¸­é‡å»ºunique_id
                        if 'meta_data' in result:
                            sample_id = result['meta_data'].get('id', 'unknown')
                            progress_score = result.get('ground_truth_score', 'unknown')
                            unique_id = f"{sample_id}_{progress_score}"
                            processed_ids.add(unique_id)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            print(f"âš ï¸  è¯»å–å·²å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        return processed_ids
    
    def extract_tags(self, response: str) -> Dict[str, str]:
        """
        ä»å“åº”ä¸­æå–ç‰¹å®šæ ‡ç­¾çš„å†…å®¹
        
        Args:
            response: GPT-5çš„å“åº”æ–‡æœ¬
        
        Returns:
            åŒ…å«æå–å†…å®¹çš„å­—å…¸
        """
        import re
        
        extracted = {}
        
        # æå–<ref>æ ‡ç­¾å†…å®¹
        ref_match = re.search(r'<ref>(.*?)</ref>', response, re.DOTALL)
        extracted['ref'] = ref_match.group(1).strip() if ref_match else None
        
        # æå–<score>æ ‡ç­¾å†…å®¹
        score_match = re.search(r'<score>(.*?)</score>', response, re.DOTALL)
        extracted['score'] = score_match.group(1).strip() if score_match else None
        
        return extracted
    
    def process_single_sample(self, sample: Dict) -> Dict:
        """
        å¤„ç†å•ä¸ªæ ·æœ¬
        
        Args:
            sample: JSONLä¸­çš„ä¸€ä¸ªæ ·æœ¬
        
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message_content = self.build_message_content(sample)
            
            # è°ƒç”¨GPT-5 API
            # æ³¨æ„ï¼šGPT-5ä½¿ç”¨max_completion_tokensè€Œä¸æ˜¯max_tokens
            api_params = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": message_content
                    }
                ],
                "temperature": 1,
                "max_completion_tokens": 3000  # GPT-5ä½¿ç”¨max_completion_tokens
            }
            
            # æ·»åŠ GPT-5ç‰¹æœ‰å‚æ•°ï¼ˆå¦‚æœæ”¯æŒï¼‰
            # æ³¨æ„ï¼šå¦‚æœè¿™äº›å‚æ•°å¯¼è‡´é”™è¯¯ï¼Œå¯ä»¥æ³¨é‡Šæ‰
            if self.model.startswith("gpt-5"):
                # api_params["verbosity"] = "medium"  # å¦‚æœä¸æ”¯æŒï¼Œæ³¨é‡Šæ­¤è¡Œ
                # api_params["reasoning_effort"] = "medium"  # å¦‚æœä¸æ”¯æŒï¼Œæ³¨é‡Šæ­¤è¡Œ
                pass  # æš‚æ—¶ä¸æ·»åŠ ç‰¹æ®Šå‚æ•°ï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜
            
            response = self.client.chat.completions.create(**api_params)
            
            # æå–å“åº”
            assistant_response = response.choices[0].message.content
            
            # æå–æ ‡ç­¾å†…å®¹
            extracted = self.extract_tags(assistant_response)
            
            # æ„å»ºè¾“å‡ºç»“æœ - æ–°æ ¼å¼
            result = {
                "ref": extracted.get('ref'),
                "score": extracted.get('score'),
                "closest_idx": sample["closest_idx"],
                "ground_truth_score": sample["progress_score"],
                "response": assistant_response,
                "meta_data": {
                    "id": sample["id"],
                    "task_goal": sample["task_goal"],
                    "tokens_used": response.usage.total_tokens,
                    "model": self.model,
                    "timestamp": datetime.now().isoformat(),
                    "status": "success"
                }
            }
            
            return result
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            if hasattr(e, 'response'):
                error_msg += f"\nAPIå“åº”: {e.response}"
            
            return {
                "ref": None,
                "score": None,
                "closest_idx": sample.get("closest_idx", ""),
                "ground_truth_score": sample.get("progress_score", ""),
                "response": None,
                "meta_data": {
                    "id": sample["id"],
                    "task_goal": sample.get("task_goal", ""),
                    "error": error_msg,
                    "traceback": traceback.format_exc(),
                    "timestamp": datetime.now().isoformat(),
                    "status": "error"
                }
            }
    
    def save_result(self, result: Dict, output_file: Path):
        """
        ä¿å­˜å•ä¸ªç»“æœåˆ°JSONLæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        
        Args:
            result: å¤„ç†ç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with write_lock:
            with open(output_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    def process_batch(self, 
                     input_file: str, 
                     output_file: str,
                     max_workers: int = 5,
                     retry_failed: bool = True,
                     limit: int = None,
                     resume: bool = False):
        """
        æ‰¹é‡å¤„ç†JSONLæ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„
            max_workers: æœ€å¤§å¹¶å‘æ•°
            retry_failed: æ˜¯å¦é‡è¯•å¤±è´¥çš„æ ·æœ¬
            limit: é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡
            resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 
        """
        # åŠ è½½è¾“å…¥æ•°æ®
        all_samples = []
        with open(input_file, 'r', encoding='utf-8') as f:
            for line in f:
                all_samples.append(json.loads(line.strip()))
        
        print(f"ğŸ“Š æ€»å…±åŠ è½½äº† {len(all_samples)} ä¸ªæ ·æœ¬")
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ–­ç‚¹ç»­ä¼ ï¼šåŠ è½½å·²å¤„ç†çš„æ ·æœ¬
        processed_ids = set()
        if resume:
            processed_ids = self.load_processed_ids(output_path)
            if processed_ids:
                print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼šå‘ç° {len(processed_ids)} ä¸ªå·²å¤„ç†æ ·æœ¬")
        else:
            # éç»­ä¼ æ¨¡å¼ï¼Œæ¸…ç©ºè¾“å‡ºæ–‡ä»¶
            if output_path.exists():
                output_path.unlink()
                print(f"ğŸ—‘ï¸  å·²æ¸…ç©ºç°æœ‰è¾“å‡ºæ–‡ä»¶")
        
        # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ ·æœ¬
        samples_to_process = []
        skipped_count = 0
        
        for sample in all_samples:
            unique_id = self.get_sample_unique_id(sample)
            if unique_id in processed_ids:
                skipped_count += 1
                continue
            samples_to_process.append(sample)
            
            # å¦‚æœè®¾ç½®äº†limitï¼Œæ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™åˆ¶
            if limit and len(samples_to_process) >= limit:
                break
        
        if skipped_count > 0:
            print(f"â­ï¸  è·³è¿‡ {skipped_count} ä¸ªå·²å¤„ç†æ ·æœ¬")
        
        if limit:
            print(f"ğŸ¯ é™åˆ¶å¤„ç†æ•°é‡: {limit}")
            samples_to_process = samples_to_process[:limit]
        
        samples = samples_to_process
        
        if not samples:
            print(f"âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–°æ ·æœ¬")
            return 0, 0
        
        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(samples)} ä¸ªæ ·æœ¬ (å¹¶å‘æ•°: {max_workers})")
        
        # ç»Ÿè®¡
        success_count = 0
        error_count = 0
        total_tokens = 0
        failed_samples = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_sample = {
                executor.submit(self.process_single_sample, sample): sample 
                for sample in samples
            }
            
            # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
            desc = "ç»­ä¼ è¿›åº¦" if resume else "å¤„ç†è¿›åº¦"
            with tqdm(total=len(samples), desc=desc) as pbar:
                for future in as_completed(future_to_sample):
                    sample = future_to_sample[future]
                    
                    try:
                        result = future.result(timeout=60)  # 60ç§’è¶…æ—¶
                        
                        # ä¿å­˜ç»“æœ
                        self.save_result(result, output_path)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        if result['meta_data']['status'] == 'success':
                            success_count += 1
                            total_tokens += result['meta_data'].get('tokens_used', 0)
                            pbar.set_postfix({
                                'âœ…': success_count,
                                'âŒ': error_count,
                                'tokens': total_tokens
                            })
                        else:
                            error_count += 1
                            failed_samples.append(sample)
                            pbar.set_postfix({
                                'âœ…': success_count,
                                'âŒ': error_count,
                                'tokens': total_tokens,
                                'last_error': result['meta_data'].get('error', '')[:50]
                            })
                        
                    except Exception as e:
                        error_count += 1
                        failed_samples.append(sample)
                        error_result = {
                            "ref": None,
                            "score": None,
                            "closest_idx": sample.get("closest_idx", ""),
                            "ground_truth_score": sample.get("progress_score", ""),
                            "response": None,
                            "meta_data": {
                                "id": sample.get("id", "unknown"),
                                "error": f"æ‰§è¡Œè¶…æ—¶æˆ–å¼‚å¸¸: {str(e)}",
                                "timestamp": datetime.now().isoformat(),
                                "status": "error"
                            }
                        }
                        self.save_result(error_result, output_path)
                        pbar.set_postfix({
                            'âœ…': success_count,
                            'âŒ': error_count,
                            'timeout': True
                        })
                    
                    pbar.update(1)
        
        # é‡è¯•å¤±è´¥çš„æ ·æœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if retry_failed and failed_samples:
            print(f"\nğŸ”„ é‡è¯• {len(failed_samples)} ä¸ªå¤±è´¥çš„æ ·æœ¬...")
            retry_success = 0
            
            with tqdm(total=len(failed_samples), desc="é‡è¯•è¿›åº¦") as pbar:
                for sample in failed_samples:
                    time.sleep(1)  # é¿å…é€Ÿç‡é™åˆ¶
                    result = self.process_single_sample(sample)
                    self.save_result(result, output_path)
                    
                    if result['meta_data']['status'] == 'success':
                        retry_success += 1
                        success_count += 1
                        error_count -= 1
                        total_tokens += result['meta_data'].get('tokens_used', 0)
                    
                    pbar.update(1)
                    pbar.set_postfix({'é‡è¯•æˆåŠŸ': retry_success})
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        total_processed = success_count + error_count
        if resume and processed_ids:
            print(f"\nğŸ“Š æœ¬æ¬¡å¤„ç†ç»Ÿè®¡:")
            print(f"  ğŸ”„ ä¹‹å‰å·²å¤„ç†: {len(processed_ids)}")
            print(f"  âœ¨ æœ¬æ¬¡å¤„ç†: {total_processed}")
            print(f"    - âœ… æˆåŠŸ: {success_count}")
            print(f"    - âŒ å¤±è´¥: {error_count}")
            print(f"  ğŸ“ˆ ç´¯è®¡å¤„ç†: {len(processed_ids) + total_processed}")
        else:
            print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"  âœ… æˆåŠŸ: {success_count}/{total_processed}")
            print(f"  âŒ å¤±è´¥: {error_count}/{total_processed}")
        
        print(f"  ğŸ’° æœ¬æ¬¡Tokenä½¿ç”¨: {total_tokens:,}")
        print(f"  ğŸ“„ ç»“æœä¿å­˜è‡³: {output_path}")
        
        # è®¡ç®—ä¼°ç®—æˆæœ¬ï¼ˆåŸºäºGPT-5-miniä»·æ ¼ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–è®¡ç®—ï¼Œå®é™…ä¸Šè¾“å…¥å’Œè¾“å‡ºtokenåº”è¯¥åˆ†å¼€è®¡ç®—
        input_cost = total_tokens * 0.25 / 1_000_000  # $0.25 per 1M input tokens
        output_cost = total_tokens * 2.0 / 1_000_000  # $2.00 per 1M output tokens
        estimated_cost = input_cost + output_cost
        print(f"  ğŸ’µ æœ¬æ¬¡ä¼°ç®—æˆæœ¬: ${estimated_cost:.4f} (ç®€åŒ–è®¡ç®—)")
        
        return success_count, error_count


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="GPT-5-mini Visual Progress Evaluation Processor"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        required=True,
        help="OpenAI APIå¯†é’¥"
    )
    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--image-dir",
        type=str,
        required=True,
        help="å›¾åƒåŸºç¡€ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-5-mini",
        choices=["gpt-5", "gpt-5-mini", "gpt-5-nano"],
        help="ä½¿ç”¨çš„GPT-5æ¨¡å‹ç‰ˆæœ¬"
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=5,
        help="æœ€å¤§å¹¶å‘å¤„ç†æ•°ï¼ˆé»˜è®¤: 5ï¼‰"
    )
    parser.add_argument(
        "--no-retry",
        action="store_true",
        help="ä¸é‡è¯•å¤±è´¥çš„æ ·æœ¬"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="å¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼ˆä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­ï¼‰"
    )
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not Path(args.input).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # éªŒè¯å›¾åƒç›®å½•
    if not Path(args.image_dir).exists():
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {args.image_dir}")
        sys.exit(1)
    
    # åˆ›å»ºå¤„ç†å™¨
    try:
        processor = VisualProgressProcessor(
            api_key=args.api_key,
            image_dir=args.image_dir,
            model=args.model
        )
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # å¼€å§‹å¤„ç†
    print(f"\n{'='*60}")
    print(f"GPT-5 Visual Progress Evaluation")
    print(f"{'='*60}")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"ğŸ–¼ï¸  å›¾åƒç›®å½•: {args.image_dir}")
    print(f"ğŸ¤– æ¨¡å‹: {args.model}")
    print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'æ˜¯' if args.resume else 'å¦'}")
    if args.limit:
        print(f"ğŸ¯ å¤„ç†é™åˆ¶: {args.limit} ä¸ªæ ·æœ¬")
    print(f"{'='*60}\n")
    
    start_time = time.time()
    
    try:
        success_count, error_count = processor.process_batch(
            input_file=args.input,
            output_file=args.output,
            max_workers=args.max_workers,
            retry_failed=not args.no_retry,
            limit=args.limit,
            resume=args.resume
        )
        
        elapsed_time = time.time() - start_time
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        
        # è¿”å›é€‚å½“çš„é€€å‡ºç 
        if error_count == 0:
            sys.exit(0)
        elif success_count > 0:
            sys.exit(1)  # éƒ¨åˆ†æˆåŠŸ
        else:
            sys.exit(2)  # å…¨éƒ¨å¤±è´¥
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        print(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()