# # # import json

# # # def remove_coin_images(input_path, output_path):
# # #     """
# # #     åˆ é™¤ jsonl æ–‡ä»¶ä¸­ images å­—æ®µä¸­åŒ…å« 'coin' çš„é¡¹ï¼Œå¹¶ç”Ÿæˆæ–°çš„æ–‡ä»¶ã€‚
# # #     å¤„ç†ç»“æœç›´æ¥æ‰“å°åœ¨å‘½ä»¤è¡Œã€‚
# # #     """
# # #     modified_count = 0
# # #     total_count = 0

# # #     with open(input_path, 'r', encoding='utf-8') as infile, \
# # #          open(output_path, 'w', encoding='utf-8') as outfile:

# # #         for line_num, line in enumerate(infile, start=1):
# # #             line = line.strip()
# # #             if not line:
# # #                 continue
# # #             total_count += 1

# # #             try:
# # #                 data = json.loads(line)
# # #             except json.JSONDecodeError as e:
# # #                 print(f"[ç¬¬ {line_num} è¡Œ] âŒ JSON è§£æé”™è¯¯: {e}")
# # #                 continue

# # #             images = data.get("images", [])
# # #             if any("coin" in str(img) for img in images):
# # #                 data.pop("images", None)
# # #                 modified_count += 1
# # #                 print(f"[ç¬¬ {line_num} è¡Œ] ğŸ§¹ åˆ é™¤ images å­—æ®µï¼ˆå« 'coin'ï¼‰")

# # #             json.dump(data, outfile, ensure_ascii=False)
# # #             outfile.write('\n')

# # #     print("\nâœ… å¤„ç†å®Œæˆï¼")
# # #     print(f"æ€»è¡Œæ•°: {total_count}")
# # #     print(f"ä¿®æ”¹è¡Œæ•°: {modified_count}")
# # #     print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")


# # # if __name__ == "__main__":
# # #     # è¾“å…¥ã€è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¯æŒ‰éœ€ä¿®æ”¹
# # #     input_file = "/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/sft_data/sft_steps_3to7.jsonl"
# # #     output_file = "/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/sft_data/sft_no_coin.jsonl"

# # #     remove_coin_images(input_file, output_file)

# # import json
# # import re

# # def add_percent_to_scores(input_path, output_path):
# #     """
# #     åœ¨ jsonl æ–‡ä»¶ä¸­ä¸º <score></score> æ ‡ç­¾å†…æ²¡æœ‰ '%' çš„æ•°å€¼åŠ ä¸Šç™¾åˆ†å·ã€‚
# #     ä¿®æ”¹ç»“æœå†™å…¥æ–°çš„æ–‡ä»¶ï¼Œå¹¶åœ¨å‘½ä»¤è¡Œæ˜¾ç¤ºä¿®æ”¹æƒ…å†µã€‚
# #     """
# #     modified_count = 0
# #     total_count = 0

# #     # åŒ¹é… <score>æ•°å­—</score> çš„æ­£åˆ™ï¼ˆä¸å« %ï¼‰
# #     score_pattern = re.compile(r"<score>(\s*[\d.]+)\s*</score>")

# #     with open(input_path, 'r', encoding='utf-8') as infile, \
# #          open(output_path, 'w', encoding='utf-8') as outfile:

# #         for line_num, line in enumerate(infile, start=1):
# #             line = line.strip()
# #             if not line:
# #                 continue
# #             total_count += 1

# #             try:
# #                 data = json.loads(line)
# #             except json.JSONDecodeError as e:
# #                 print(f"[ç¬¬ {line_num} è¡Œ] âŒ JSON è§£æé”™è¯¯: {e}")
# #                 continue

# #             modified = False

# #             # å¦‚æœ assistant å†…å®¹é‡Œæœ‰ <score> æ ‡ç­¾ï¼Œå¤„ç†å®ƒ
# #             if "messages" in data:
# #                 for msg in data["messages"]:
# #                     if msg.get("role") == "assistant" and isinstance(msg.get("content"), str):
# #                         content = msg["content"]

# #                         # æŸ¥æ‰¾æ‰€æœ‰æ²¡æœ‰ç™¾åˆ†å·çš„ score æ ‡ç­¾
# #                         def add_percent(match):
# #                             nonlocal modified
# #                             modified = True
# #                             value = match.group(1).strip()
# #                             return f"<score>{value}%</score>"

# #                         new_content = score_pattern.sub(add_percent, content)
# #                         msg["content"] = new_content

# #             if modified:
# #                 modified_count += 1
# #                 print(f"[ç¬¬ {line_num} è¡Œ] âœ… å·²ä¸º <score> è¡¥ä¸Š '%'")

# #             json.dump(data, outfile, ensure_ascii=False)
# #             outfile.write('\n')

# #     print("\nâœ… å¤„ç†å®Œæˆï¼")
# #     print(f"æ€»è¡Œæ•°: {total_count}")
# #     print(f"ä¿®æ”¹è¡Œæ•°: {modified_count}")
# #     print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")


# # if __name__ == "__main__":
# #     # è¾“å…¥ä¸è¾“å‡ºè·¯å¾„ï¼Œå¯æŒ‰éœ€ä¿®æ”¹
# #     input_file = "/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/sft_data/sft_no_coin.jsonl"
# #     output_file = "/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/sft_data/sft_final.jsonl"

# #     add_percent_to_scores(input_file, output_file)

# # #!/usr/bin/env python3
# # import json
# # from tqdm import tqdm
# # import argparse
# # import re
# # import os

# # def count_image_tokens(text):
# #     """ç»Ÿè®¡ <image> å‡ºç°æ¬¡æ•°"""
# #     return len(re.findall(r"<image>", text))

# # def check_sft_file(input_path, output_path=None):
# #     bad_samples = []
# #     total = 0
# #     kept = 0

# #     with open(input_path, "r", encoding="utf-8") as fin:
# #         lines = fin.readlines()

# #     if output_path:
# #         fout = open(output_path, "w", encoding="utf-8")

# #     for i, line in enumerate(tqdm(lines, desc="Checking samples")):
# #         total += 1
# #         try:
# #             obj = json.loads(line)
# #         except Exception as e:
# #             bad_samples.append((i+1, "JSONDecodeError", str(e)))
# #             continue

# #         # æå–æ‰€æœ‰æ¶ˆæ¯æ–‡æœ¬
# #         messages = obj.get("messages", [])
# #         if not messages:
# #             bad_samples.append((i+1, "NoMessages", "Missing 'messages' field"))
# #             continue

# #         text = "".join(m.get("content", "") for m in messages)
# #         num_tokens = count_image_tokens(text)
# #         num_images = len(obj.get("images", []))

# #         if num_tokens != num_images:
# #             bad_samples.append((i+1, f"{num_tokens} <image>", f"{num_images} images"))
# #             continue

# #         if output_path:
# #             fout.write(json.dumps(obj, ensure_ascii=False) + "\n")
# #             kept += 1

# #     if output_path:
# #         fout.close()

# #     print("\n=== æ£€æŸ¥ç»“æœ ===")
# #     print(f"æ€»æ ·æœ¬æ•°: {total}")
# #     print(f"é”™è¯¯æ ·æœ¬æ•°: {len(bad_samples)}")
# #     if output_path:
# #         print(f"å·²ä¿å­˜å¹²å‡€æ ·æœ¬: {kept} -> {output_path}")

# #     if bad_samples:
# #         print("\nå‰ 10 ä¸ªé—®é¢˜æ ·æœ¬:")
# #         for idx, token_info, img_info in bad_samples[:10]:
# #             print(f"  è¡Œ {idx}: {token_info} / {img_info}")

# #     return bad_samples


# # if __name__ == "__main__":
# #     parser = argparse.ArgumentParser(description="æ£€æŸ¥å¹¶æ¸…æ´— SFT æ•°æ®é›†ä¸­çš„ <image> ä¸åŒ¹é…æ ·æœ¬")
# #     parser.add_argument("--input", required=True, help="è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„")
# #     parser.add_argument("--output", help="è¾“å‡ºæ¸…æ´—åçš„æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
# #     args = parser.parse_args()

# #     if not os.path.exists(args.input):
# #         raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {args.input}")

# #     check_sft_file(args.input, args.output)



# import json
# import re
# from tqdm import tqdm
# import argparse
# import os

# def count_image_tokens(text):
#     """ç»Ÿè®¡ <image> å‡ºç°æ¬¡æ•°"""
#     return len(re.findall(r"<image>", text))

# def clean_sft_file(input_path, output_path):
#     total, kept, removed = 0, 0, 0

#     with open(input_path, "r", encoding="utf-8") as fin, open(output_path, "w", encoding="utf-8") as fout:
#         for i, line in enumerate(tqdm(fin, desc="Cleaning dataset")):
#             total += 1
#             try:
#                 obj = json.loads(line)
#             except Exception as e:
#                 removed += 1
#                 continue

#             messages = obj.get("messages", [])
#             if not messages:
#                 removed += 1
#                 continue

#             text = "".join(m.get("content", "") for m in messages)
#             num_tokens = count_image_tokens(text)
#             num_images = len(obj.get("images", []))

#             # æ¡ä»¶ï¼šæ•°é‡åŒ¹é…æ‰èƒ½ä¿ç•™
#             if num_tokens == num_images:
#                 fout.write(json.dumps(obj, ensure_ascii=False) + "\n")
#                 kept += 1
#             else:
#                 removed += 1

#     print("\n=== æ¸…ç†å®Œæˆ ===")
#     print(f"æ€»æ ·æœ¬æ•°: {total}")
#     print(f"ä¿ç•™æ ·æœ¬æ•°: {kept}")
#     print(f"åˆ é™¤æ ·æœ¬æ•°: {removed}")
#     print(f"å¹²å‡€æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser(description="ä¸€é”®æ¸…é™¤ SFT æ•°æ®é›†ä¸­ <image> æ•°é‡ä¸åŒ¹é…çš„æ ·æœ¬")
#     parser.add_argument("--input", required=True, help="è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„")
#     parser.add_argument("--output", required=True, help="è¾“å‡ºæ¸…æ´—åæ–‡ä»¶è·¯å¾„")
#     args = parser.parse_args()

#     if not os.path.exists(args.input):
#         raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {args.input}")

#     clean_sft_file(args.input, args.output)

# import json

# file_path = "/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/sft_data/sft_final.jsonl"

# count_total = 0
# count_len1 = 0

# with open(file_path, "r", encoding="utf-8") as f:
#     for line in f:
#         data = json.loads(line)
#         if "images" in data:
#             count_total += 1
#             if isinstance(data["images"], list) and len(data["images"]) == 1:
#                 count_len1 += 1

# if count_total > 0:
#     ratio = count_len1 / count_total
#     print(f"æ€»æ ·æœ¬æ•°: {count_total}")
#     print(f"imagesé•¿åº¦ä¸º1çš„æ ·æœ¬æ•°: {count_len1}")
#     print(f"æ¯”ä¾‹: {ratio:.2%}")
# else:
#     print("æœªæ‰¾åˆ°åŒ…å«imageså­—æ®µçš„æ•°æ®ã€‚")
