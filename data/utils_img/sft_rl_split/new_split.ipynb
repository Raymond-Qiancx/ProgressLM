{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===================== é…ç½®åŒº =====================\n",
    "INPUT_JSONL = '/home/vcj9002/jianshu/chengxuan/ProgressLM/data/train/rl/text_rl_all_3to7_clean.jsonl'\n",
    "OUTPUT_DIR  = '/home/vcj9002/jianshu/chengxuan/ProgressLM/data/train/text_demo/new'\n",
    "SFT_JSONL   = os.path.join(OUTPUT_DIR, 'new_text_sft.jsonl')\n",
    "RL_JSONL    = os.path.join(OUTPUT_DIR, 'rl_text_clean_other.jsonl')\n",
    "SPLIT_RATIO = 0.1   # SFT å  10%ï¼ŒRL å  90%\n",
    "SEED = 42\n",
    "# =================================================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def extract_action_type(id_string: str):\n",
    "    parts = id_string.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def load_jsonl(jsonl_path: str):\n",
    "    data = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®\")\n",
    "    return data\n",
    "\n",
    "def group_by_trajectory(data):\n",
    "    \"\"\"\n",
    "    å°†æ•°æ®æŒ‰å®Œæ•´ idï¼ˆå³è½¨è¿¹ï¼‰èšåˆã€‚\n",
    "    è¿”å›: {action_type: {trajectory_id: [items...] } }\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(lambda: defaultdict(list))\n",
    "    for item in data:\n",
    "        tid = item.get('id', '')\n",
    "        act = extract_action_type(tid)\n",
    "        if act:\n",
    "            grouped[act][tid].append(item)\n",
    "    return grouped\n",
    "\n",
    "def dump_jsonl(data, out_path: str):\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "    # 1) åŠ è½½æ•°æ®\n",
    "    data = load_jsonl(INPUT_JSONL)\n",
    "\n",
    "    # 2) æŒ‰ç±»åˆ« & è½¨è¿¹åˆ†ç»„\n",
    "    grouped = group_by_trajectory(data)\n",
    "    print(f\"âœ“ å…±å‘ç° {len(grouped)} ä¸ªç±»åˆ«ï¼ˆåŸºäº extract_action_typeï¼‰\\n\")\n",
    "\n",
    "    # 3) åˆ†å±‚åˆ’åˆ† SFT / RL\n",
    "    sft_data, rl_data = [], []\n",
    "\n",
    "    category_stats = []  # ç”¨äºæ‰“å°ç»Ÿè®¡\n",
    "    for act, traj_map in grouped.items():\n",
    "        traj_ids = list(traj_map.keys())\n",
    "        random.shuffle(traj_ids)\n",
    "\n",
    "        # è®¡ç®— SFT è½¨è¿¹æ•°é‡ï¼Œç¡®ä¿è‡³å°‘æœ‰1ä¸ª\n",
    "        sft_count = max(1, int(len(traj_ids) * SPLIT_RATIO))\n",
    "        \n",
    "        # ç‰¹æ®Šæƒ…å†µå¤„ç†ï¼šå¦‚æœåªæœ‰1ä¸ªè½¨è¿¹\n",
    "        if len(traj_ids) == 1:\n",
    "            # é€‰é¡¹1ï¼šåŒæ—¶æ”¾å…¥SFTå’ŒRLï¼ˆæ•°æ®ä¼šé‡å¤ï¼‰\n",
    "            sft_traj = traj_ids[:]\n",
    "            rl_traj = traj_ids[:]\n",
    "            \n",
    "            # é€‰é¡¹2ï¼šåªæ”¾å…¥SFTï¼ˆå¦‚æœä¸æƒ³è¦æ•°æ®é‡å¤ï¼Œä½¿ç”¨è¿™ä¸ªï¼‰\n",
    "            # sft_traj = traj_ids[:]\n",
    "            # rl_traj = []\n",
    "        else:\n",
    "            # æ­£å¸¸æƒ…å†µï¼šæŒ‰æ¯”ä¾‹åˆ†é…ï¼Œä½†ç¡®ä¿SFTè‡³å°‘æœ‰1ä¸ª\n",
    "            sft_traj = traj_ids[:sft_count]\n",
    "            rl_traj = traj_ids[sft_count:]\n",
    "\n",
    "        # æ”¶é›†æ•°æ®\n",
    "        sft_items = [item for tid in sft_traj for item in traj_map[tid]]\n",
    "        rl_items = [item for tid in rl_traj for item in traj_map[tid]]\n",
    "\n",
    "        sft_data.extend(sft_items)\n",
    "        rl_data.extend(rl_items)\n",
    "\n",
    "        # è®°å½•ç»Ÿè®¡\n",
    "        category_stats.append({\n",
    "            'ç±»åˆ«': act,\n",
    "            'æ€»è½¨è¿¹æ•°': len(traj_ids),\n",
    "            'SFT_è½¨è¿¹æ•°': len(sft_traj),\n",
    "            'RL_è½¨è¿¹æ•°': len(rl_traj),\n",
    "            'SFT_æ ·æœ¬æ•°': len(sft_items),\n",
    "            'RL_æ ·æœ¬æ•°': len(rl_items),\n",
    "            'é‡å¤': 'æ˜¯' if len(traj_ids) == 1 and len(rl_traj) > 0 else 'å¦'\n",
    "        })\n",
    "\n",
    "    # 4) å†™å‡ºæ–‡ä»¶\n",
    "    dump_jsonl(sft_data, SFT_JSONL)\n",
    "    dump_jsonl(rl_data, RL_JSONL)\n",
    "\n",
    "    # 5) æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n====== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ======\")\n",
    "    print(f\"æ€»ç±»åˆ«æ•°: {len(category_stats)}\")\n",
    "    print(f\"ç›®æ ‡æ¯”ä¾‹ SFT : RL = {SPLIT_RATIO:.0%} : {1-SPLIT_RATIO:.0%}\\n\")\n",
    "\n",
    "    print(\"ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'ç±»åˆ«':20s} | {'æ€»è½¨è¿¹':6s} | {'SFTè½¨è¿¹':7s} {'RLè½¨è¿¹':7s} | {'SFTæ ·æœ¬':7s} {'RLæ ·æœ¬':7s} | {'é‡å¤':4s}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_trajs = 0\n",
    "    single_traj_categories = 0\n",
    "    \n",
    "    for stat in category_stats:\n",
    "        print(f\"{stat['ç±»åˆ«']:20s} | {stat['æ€»è½¨è¿¹æ•°']:6d} | \"\n",
    "              f\"{stat['SFT_è½¨è¿¹æ•°']:7d} {stat['RL_è½¨è¿¹æ•°']:7d} | \"\n",
    "              f\"{stat['SFT_æ ·æœ¬æ•°']:7d} {stat['RL_æ ·æœ¬æ•°']:7d} | \"\n",
    "              f\"{stat['é‡å¤']:4s}\")\n",
    "        total_trajs += stat['æ€»è½¨è¿¹æ•°']\n",
    "        if stat['æ€»è½¨è¿¹æ•°'] == 1:\n",
    "            single_traj_categories += 1\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"æ±‡æ€»: SFT æ€»æ ·æœ¬æ•°: {len(sft_data)}   RL æ€»æ ·æœ¬æ•°: {len(rl_data)}\")\n",
    "    print(f\"      æ€»è½¨è¿¹æ•°: {total_trajs}   åªæœ‰1ä¸ªè½¨è¿¹çš„ç±»åˆ«æ•°: {single_traj_categories}\")\n",
    "    \n",
    "    # éªŒè¯æ¯ä¸ªç±»åˆ«éƒ½æœ‰SFTæ•°æ®\n",
    "    missing_sft = [stat['ç±»åˆ«'] for stat in category_stats if stat['SFT_è½¨è¿¹æ•°'] == 0]\n",
    "    if missing_sft:\n",
    "        print(f\"\\nâš ï¸ è­¦å‘Šï¼šä»¥ä¸‹ç±»åˆ«æ²¡æœ‰SFTæ•°æ®: {missing_sft}\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰ {len(category_stats)} ä¸ªç±»åˆ«éƒ½æœ‰è‡³å°‘1ä¸ªè½¨è¿¹åœ¨SFTä¸­\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘‰ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:\\n   - {SFT_JSONL}\\n   - {RL_JSONL}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
