{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5c504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸåŠ è½½ 16359 æ¡æ•°æ®\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š åŠ¨ä½œç±»å‹ç»Ÿè®¡åˆ†æ\n",
      "============================================================\n",
      "\n",
      "æ€»è®¡ï¼š\n",
      "  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: 23\n",
      "  â€¢ Trajectoryæ€»æ•°: 957\n",
      "  â€¢ æ ·æœ¬æ€»æ•°: 16359\n",
      "\n",
      "è¯¦ç»†ç»Ÿè®¡ï¼š\n",
      "                                                         åŠ¨ä½œç±»å‹  Trajectoryæ•°é‡  æ ·æœ¬æ•°é‡\n",
      "                                cylinder_pick_box_place_close            56   954\n",
      "                                                   gear_place            48   945\n",
      "                                          throw_battery_twice            45   942\n",
      "                                                    nut_place            45   894\n",
      "                                      place_button_then_press            50   888\n",
      "                                                throw_battery            48   873\n",
      "                               battery_insertion_with_pullout            49   843\n",
      "                                      plug_pullout_then_press            46   828\n",
      "                                                seal_stamping            42   804\n",
      "                                            plug_insertion_v2            43   786\n",
      "                                                   wipe_panel            48   741\n",
      "                                               plug_insertion            40   699\n",
      "                                         tool_liftn_box_place            39   681\n",
      "                                                 place_button            45   672\n",
      "                                brick_piled_then_press_thrice            40   645\n",
      "                                            plug_extract_from            36   645\n",
      "                                        pour_bread_then_place            36   624\n",
      "           pick_shelf_insert_machine_press_switch_place_plate            33   585\n",
      "                                                 plug_pullout            31   579\n",
      "                          push_bewak_pick_machine_place_plate            37   525\n",
      "                                          switch_manipulation            29   471\n",
      "                                                   plate_push            46   411\n",
      "push_break_pick_shelf_insert_machine_press_switch_place_plate            25   324\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class ActionAnalyzer:\n",
    "    \"\"\"åˆ†æJSONLæ ¼å¼çš„åŠ¨ä½œç±»å‹æ•°æ®\"\"\"\n",
    "    \n",
    "    def __init__(self, jsonl_path):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–åˆ†æå™¨\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        jsonl_path : str\n",
    "            JSONLæ–‡ä»¶è·¯å¾„\n",
    "        \"\"\"\n",
    "        self.jsonl_path = jsonl_path\n",
    "        self.data = []\n",
    "        self.stats = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"åŠ è½½JSONLæ•°æ®\"\"\"\n",
    "        with open(self.jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    self.data.append(json.loads(line))\n",
    "        print(f\"âœ“ æˆåŠŸåŠ è½½ {len(self.data)} æ¡æ•°æ®\")\n",
    "        return self\n",
    "    \n",
    "    def extract_action_type(self, id_string):\n",
    "        \"\"\"\n",
    "        ä»IDä¸­æå–åŠ¨ä½œç±»å‹\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        id_string : str\n",
    "            æ ¼å¼: æ•°æ®é›†åç§°/åŠ¨ä½œç±»å‹/æ—¶é—´æˆ³\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        str : åŠ¨ä½œç±»å‹\n",
    "        \"\"\"\n",
    "        parts = id_string.split('/')\n",
    "        if len(parts) >= 2:\n",
    "            return parts[1]  # è¿”å›ä¸¤ä¸ªæ–œæ ä¹‹é—´çš„å†…å®¹\n",
    "        return None\n",
    "    \n",
    "    def analyze(self):\n",
    "        \"\"\"åˆ†ææ•°æ®å¹¶ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        action_data = defaultdict(lambda: {'trajectories': set(), 'samples': 0})\n",
    "        \n",
    "        for item in self.data:\n",
    "            id_string = item.get('id', '')\n",
    "            action_type = self.extract_action_type(id_string)\n",
    "            \n",
    "            if action_type:\n",
    "                # ç»Ÿè®¡trajectoryï¼ˆå®Œæ•´çš„IDä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰\n",
    "                action_data[action_type]['trajectories'].add(id_string)\n",
    "                # ç»Ÿè®¡æ ·æœ¬æ•°\n",
    "                action_data[action_type]['samples'] += 1\n",
    "        \n",
    "        # è½¬æ¢ä¸ºDataFrame\n",
    "        stats_list = []\n",
    "        for action_type, info in action_data.items():\n",
    "            stats_list.append({\n",
    "                'åŠ¨ä½œç±»å‹': action_type,\n",
    "                'Trajectoryæ•°é‡': len(info['trajectories']),\n",
    "                'æ ·æœ¬æ•°é‡': info['samples']\n",
    "            })\n",
    "        \n",
    "        self.stats = pd.DataFrame(stats_list).sort_values('æ ·æœ¬æ•°é‡', ascending=False)\n",
    "        return self\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"æ‰“å°ç»Ÿè®¡æ‘˜è¦\"\"\"\n",
    "        if self.stats is None:\n",
    "            print(\"è¯·å…ˆè¿è¡Œ analyze() æ–¹æ³•\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š åŠ¨ä½œç±»å‹ç»Ÿè®¡åˆ†æ\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\næ€»è®¡ï¼š\")\n",
    "        print(f\"  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: {len(self.stats)}\")\n",
    "        print(f\"  â€¢ Trajectoryæ€»æ•°: {self.stats['Trajectoryæ•°é‡'].sum()}\")\n",
    "        print(f\"  â€¢ æ ·æœ¬æ€»æ•°: {self.stats['æ ·æœ¬æ•°é‡'].sum()}\")\n",
    "        \n",
    "        print(f\"\\nè¯¦ç»†ç»Ÿè®¡ï¼š\")\n",
    "        print(self.stats.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        \n",
    "    def plot_statistics(self, figsize=(14, 6)):\n",
    "        \"\"\"ç»˜åˆ¶ç»Ÿè®¡å›¾è¡¨\"\"\"\n",
    "        if self.stats is None:\n",
    "            print(\"è¯·å…ˆè¿è¡Œ analyze() æ–¹æ³•\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # å›¾1ï¼šTrajectoryæ•°é‡\n",
    "        axes[0].barh(self.stats['åŠ¨ä½œç±»å‹'], self.stats['Trajectoryæ•°é‡'], \n",
    "                     color='steelblue', alpha=0.8)\n",
    "        axes[0].set_xlabel('Trajectoryæ•°é‡', fontsize=11)\n",
    "        axes[0].set_title('å„åŠ¨ä½œç±»å‹çš„Trajectoryæ•°é‡', fontsize=12, fontweight='bold')\n",
    "        axes[0].grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # å›¾2ï¼šæ ·æœ¬æ•°é‡\n",
    "        axes[1].barh(self.stats['åŠ¨ä½œç±»å‹'], self.stats['æ ·æœ¬æ•°é‡'], \n",
    "                     color='coral', alpha=0.8)\n",
    "        axes[1].set_xlabel('æ ·æœ¬æ•°é‡', fontsize=11)\n",
    "        axes[1].set_title('å„åŠ¨ä½œç±»å‹çš„æ ·æœ¬æ•°é‡', fontsize=12, fontweight='bold')\n",
    "        axes[1].grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        \"\"\"è¿”å›ç»Ÿè®¡DataFrame\"\"\"\n",
    "        return self.stats\n",
    "    \n",
    "    def export_to_csv(self, output_path='action_statistics.csv'):\n",
    "        \"\"\"å¯¼å‡ºç»Ÿè®¡ç»“æœåˆ°CSV\"\"\"\n",
    "        if self.stats is None:\n",
    "            print(\"è¯·å…ˆè¿è¡Œ analyze() æ–¹æ³•\")\n",
    "            return\n",
    "        \n",
    "        self.stats.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ“ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "\n",
    "\n",
    "# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================\n",
    "\n",
    "# 1. åˆ›å»ºåˆ†æå™¨å¹¶åŠ è½½æ•°æ®\n",
    "analyzer = ActionAnalyzer('/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/annotation/h5_tienkung_xsens_frm.jsonl')  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„\n",
    "analyzer.load_data()\n",
    "\n",
    "# 2. æ‰§è¡Œåˆ†æ\n",
    "analyzer.analyze()\n",
    "\n",
    "# 3. æ‰“å°ç»Ÿè®¡æ‘˜è¦\n",
    "analyzer.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180ba5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸåŠ è½½ 16359 æ¡æ•°æ®\n",
      "âœ“ å·²å†™å‡º Train: 12849 æ¡ -> ./splits/train.jsonl\n",
      "âœ“ å·²å†™å‡º Test : 3510 æ¡ -> ./splits/test.jsonl\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Train ç»Ÿè®¡\n",
      "============================================================\n",
      "  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: 18\n",
      "  â€¢ Trajectoryæ€»æ•°: 761\n",
      "  â€¢ æ ·æœ¬æ€»æ•°: 12849\n",
      "\n",
      "è¯¦ç»†ç»Ÿè®¡ï¼š\n",
      "                                                         åŠ¨ä½œç±»å‹  Trajectoryæ•°é‡  æ ·æœ¬æ•°é‡\n",
      "                                cylinder_pick_box_place_close            56   954\n",
      "                                                   gear_place            48   945\n",
      "                                                    nut_place            45   894\n",
      "                                      place_button_then_press            50   888\n",
      "                                                throw_battery            48   873\n",
      "                               battery_insertion_with_pullout            49   843\n",
      "                                                seal_stamping            42   804\n",
      "                                            plug_insertion_v2            43   786\n",
      "                                                   wipe_panel            48   741\n",
      "                                               plug_insertion            40   699\n",
      "                                         tool_liftn_box_place            39   681\n",
      "                                                 place_button            45   672\n",
      "                                            plug_extract_from            36   645\n",
      "           pick_shelf_insert_machine_press_switch_place_plate            33   585\n",
      "                                                 plug_pullout            31   579\n",
      "                          push_bewak_pick_machine_place_plate            37   525\n",
      "                                                   plate_push            46   411\n",
      "push_break_pick_shelf_insert_machine_press_switch_place_plate            25   324\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Test ç»Ÿè®¡\n",
      "============================================================\n",
      "  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: 5\n",
      "  â€¢ Trajectoryæ€»æ•°: 196\n",
      "  â€¢ æ ·æœ¬æ€»æ•°: 3510\n",
      "\n",
      "è¯¦ç»†ç»Ÿè®¡ï¼š\n",
      "                         åŠ¨ä½œç±»å‹  Trajectoryæ•°é‡  æ ·æœ¬æ•°é‡\n",
      "          throw_battery_twice            45   942\n",
      "      plug_pullout_then_press            46   828\n",
      "brick_piled_then_press_thrice            40   645\n",
      "        pour_bread_then_place            36   624\n",
      "          switch_manipulation            29   471\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ æ•´ä½“å æ¯”ï¼ˆæŒ‰æ ·æœ¬/trajectory/ç±»åˆ«æ•°ï¼‰\n",
      "  â€¢ Test æ ·æœ¬å æ¯”: 3510/16359 = 21.46%\n",
      "  â€¢ Test Trajectoryå æ¯”: 196/957 = 20.48%\n",
      "  â€¢ Test ç±»åˆ«å æ¯”: 5/23 = 21.74%\n",
      "\n",
      "âœ… åˆ‡åˆ†å®Œæˆã€‚ç±»åˆ«äº’æ–¥ï¼šTest = 5 ç±»ï¼›Train = å…¶ä½™å…¨éƒ¨ç±»åˆ«ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===================== é…ç½®åŒº =====================\n",
    "# è¾“å…¥ä¸è¾“å‡º\n",
    "INPUT_JSONL = '/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/annotation/h5_tienkung_xsens_frm.jsonl'  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„\n",
    "OUTPUT_DIR  = './splits'  # è¾“å‡ºç›®å½•ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºï¼‰\n",
    "TRAIN_JSONL = os.path.join(OUTPUT_DIR, 'train.jsonl')\n",
    "TEST_JSONL  = os.path.join(OUTPUT_DIR, 'test.jsonl')\n",
    "\n",
    "# å›ºå®šæµ‹è¯•é›† 5 ä¸ªç±»åˆ«ï¼ˆå…¶ä½™å…¨éƒ¨ä½œä¸ºè®­ç»ƒï¼‰\n",
    "TEST_CLASSES = {\n",
    "    'brick_piled_then_press_thrice',\n",
    "    'plug_pullout_then_press',\n",
    "    'switch_manipulation',\n",
    "    'pour_bread_then_place',\n",
    "    'throw_battery_twice',\n",
    "}\n",
    "# =================================================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def extract_action_type(id_string: str):\n",
    "    \"\"\"\n",
    "    ä»IDä¸­æå–åŠ¨ä½œç±»å‹\n",
    "    çº¦å®š: æ ¼å¼ä¸º æ•°æ®é›†åç§°/åŠ¨ä½œç±»å‹/æ—¶é—´æˆ³ æˆ–ç›¸ä¼¼ï¼ˆè‡³å°‘åŒ…å«ä¸¤æ®µï¼‰\n",
    "    \"\"\"\n",
    "    parts = id_string.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def load_jsonl(jsonl_path: str):\n",
    "    data = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®\")\n",
    "    return data\n",
    "\n",
    "def split_by_classes(data, test_classes: set):\n",
    "    \"\"\"æ ¹æ®ç±»åˆ«é›†åˆåˆ’åˆ† train/testï¼ˆç±»åˆ«äº’æ–¥ï¼‰\"\"\"\n",
    "    train, test = [], []\n",
    "    for item in data:\n",
    "        act = extract_action_type(item.get('id', ''))\n",
    "        if act in test_classes:\n",
    "            test.append(item)\n",
    "        else:\n",
    "            train.append(item)\n",
    "    return train, test\n",
    "\n",
    "def dump_jsonl(data, out_path: str):\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def summarize_split(data, title: str):\n",
    "    \"\"\"è¾“å‡ºè¯¥ split å†…çš„åŸºç¡€ç»Ÿè®¡ï¼ˆæ ·æœ¬/trajectory/æŒ‰ç±»åˆ«åˆ†å¸ƒï¼‰\"\"\"\n",
    "    # ç»Ÿè®¡\n",
    "    action_data = defaultdict(lambda: {'trajectories': set(), 'samples': 0})\n",
    "    for item in data:\n",
    "        id_string = item.get('id', '')\n",
    "        action_type = extract_action_type(id_string)\n",
    "        if action_type:\n",
    "            # æŒ‰ä½ çš„åŸå§‹é€»è¾‘ï¼šä»¥å®Œæ•´ id ä½œä¸º trajectory å”¯ä¸€æ ‡è¯†\n",
    "            action_data[action_type]['trajectories'].add(id_string)\n",
    "            action_data[action_type]['samples'] += 1\n",
    "\n",
    "    # è½¬ DataFrame\n",
    "    rows = []\n",
    "    for act, info in action_data.items():\n",
    "        rows.append({\n",
    "            'åŠ¨ä½œç±»å‹': act,\n",
    "            'Trajectoryæ•°é‡': len(info['trajectories']),\n",
    "            'æ ·æœ¬æ•°é‡': info['samples']\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values('æ ·æœ¬æ•°é‡', ascending=False)\n",
    "\n",
    "    # æ±‡æ€»\n",
    "    n_actions = len(df)\n",
    "    n_traj = int(df['Trajectoryæ•°é‡'].sum()) if not df.empty else 0\n",
    "    n_samples = int(df['æ ·æœ¬æ•°é‡'].sum()) if not df.empty else 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ“Š {title} ç»Ÿè®¡\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: {n_actions}\")\n",
    "    print(f\"  â€¢ Trajectoryæ€»æ•°: {n_traj}\")\n",
    "    print(f\"  â€¢ æ ·æœ¬æ€»æ•°: {n_samples}\")\n",
    "    if not df.empty:\n",
    "        print(\"\\nè¯¦ç»†ç»Ÿè®¡ï¼š\")\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nè¯¥ split ä¸ºç©ºã€‚\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    return {\n",
    "        'n_actions': n_actions,\n",
    "        'n_traj': n_traj,\n",
    "        'n_samples': n_samples,\n",
    "        'df': df\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "    # 1) è¯»å…¥\n",
    "    data = load_jsonl(INPUT_JSONL)\n",
    "\n",
    "    # 2) åˆ‡åˆ†ï¼ˆç±»åˆ«äº’æ–¥ï¼‰\n",
    "    train, test = split_by_classes(data, TEST_CLASSES)\n",
    "\n",
    "    # 3) å†™å‡º\n",
    "    dump_jsonl(train, TRAIN_JSONL)\n",
    "    dump_jsonl(test, TEST_JSONL)\n",
    "    print(f\"âœ“ å·²å†™å‡º Train: {len(train)} æ¡ -> {TRAIN_JSONL}\")\n",
    "    print(f\"âœ“ å·²å†™å‡º Test : {len(test)} æ¡ -> {TEST_JSONL}\")\n",
    "\n",
    "    # 4) ç»Ÿè®¡ï¼ˆåˆ†åˆ«å¯¹ Train/Testï¼‰\n",
    "    train_stat = summarize_split(train, \"Train\")\n",
    "    test_stat  = summarize_split(test,  \"Test\")\n",
    "\n",
    "    # 5) æ±‡æ€»æ¯”ä¾‹ï¼ˆä¾¿äºå¿«é€Ÿ sanity checkï¼‰\n",
    "    total_samples = train_stat['n_samples'] + test_stat['n_samples']\n",
    "    total_traj    = train_stat['n_traj'] + test_stat['n_traj']\n",
    "    total_actions = train_stat['n_actions'] + test_stat['n_actions']  # åº”ä¸ºå…¨ä½“ç±»åˆ«æ•°é‡\n",
    "\n",
    "    print(\"ğŸ“Œ æ•´ä½“å æ¯”ï¼ˆæŒ‰æ ·æœ¬/trajectory/ç±»åˆ«æ•°ï¼‰\")\n",
    "    if total_samples > 0:\n",
    "        print(f\"  â€¢ Test æ ·æœ¬å æ¯”: {test_stat['n_samples']}/{total_samples} = {test_stat['n_samples']/total_samples:.2%}\")\n",
    "    if total_traj > 0:\n",
    "        print(f\"  â€¢ Test Trajectoryå æ¯”: {test_stat['n_traj']}/{total_traj} = {test_stat['n_traj']/total_traj:.2%}\")\n",
    "    if total_actions > 0:\n",
    "        print(f\"  â€¢ Test ç±»åˆ«å æ¯”: {test_stat['n_actions']}/{total_actions} = {test_stat['n_actions']/total_actions:.2%}\")\n",
    "\n",
    "    print(\"\\nâœ… åˆ‡åˆ†å®Œæˆã€‚ç±»åˆ«äº’æ–¥ï¼šTest = 5 ç±»ï¼›Train = å…¶ä½™å…¨éƒ¨ç±»åˆ«ã€‚\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fcacfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812fbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸåŠ è½½ 12849 æ¡æ•°æ®\n",
      "âœ“ å…±å‘ç° 18 ä¸ªç±»åˆ«ï¼ˆåŸºäº extract_action_typeï¼‰\n",
      "\n",
      "\n",
      "====== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ======\n",
      "æ€»ç±»åˆ«æ•°: 18\n",
      "SFT : RL = 20% : 80%\n",
      "\n",
      "ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\n",
      "------------------------------------------------------------\n",
      "ç±»åˆ«                        | SFTè½¨è¿¹   RLè½¨è¿¹    SFTæ ·æœ¬   RLæ ·æœ¬   \n",
      "------------------------------------------------------------\n",
      "battery_insertion_with_pullout |       9      40     162     681\n",
      "cylinder_pick_box_place_close |      11      45     198     756\n",
      "pick_shelf_insert_machine_press_switch_place_plate |       6      27     108     477\n",
      "plate_push                |       9      37      84     327\n",
      "place_button              |       9      36     135     537\n",
      "plug_extract_from         |       7      29     129     516\n",
      "place_button_then_press   |      10      40     186     702\n",
      "plug_pullout              |       6      25     117     462\n",
      "seal_stamping             |       8      34     147     657\n",
      "nut_place                 |       9      36     180     714\n",
      "plug_insertion_v2         |       8      35     141     645\n",
      "plug_insertion            |       8      32     153     546\n",
      "gear_place                |       9      39     183     762\n",
      "push_break_pick_shelf_insert_machine_press_switch_place_plate |       5      20      60     264\n",
      "push_bewak_pick_machine_place_plate |       7      30     108     417\n",
      "wipe_panel                |       9      39     135     606\n",
      "throw_battery             |       9      39     153     720\n",
      "tool_liftn_box_place      |       7      32     111     570\n",
      "------------------------------------------------------------\n",
      "SFT æ€»æ ·æœ¬: 2490   RL æ€»æ ·æœ¬: 10359\n",
      "ğŸ‘‰ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:\n",
      "   - /home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_tienkung_xsens_frm/h5_tienkung_xsens_sft.jsonl\n",
      "   - /home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_tienkung_xsens_frm/h5_tienkung_xsens_rl.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===================== é…ç½®åŒº =====================\n",
    "INPUT_JSONL = '/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_tienkung_xsens_frm/h5_tienkung_xsens_frm_train.jsonl'\n",
    "OUTPUT_DIR  = '/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_tienkung_xsens_frm'\n",
    "SFT_JSONL   = os.path.join(OUTPUT_DIR, 'h5_tienkung_xsens_sft.jsonl')\n",
    "RL_JSONL    = os.path.join(OUTPUT_DIR, 'h5_tienkung_xsens_rl.jsonl')\n",
    "SPLIT_RATIO = 0.2   # SFT å  20%ï¼ŒRL å  80%\n",
    "SEED = 42\n",
    "# =================================================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def extract_action_type(id_string: str):\n",
    "    parts = id_string.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def load_jsonl(jsonl_path: str):\n",
    "    data = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®\")\n",
    "    return data\n",
    "\n",
    "def group_by_trajectory(data):\n",
    "    \"\"\"\n",
    "    å°†æ•°æ®æŒ‰å®Œæ•´ idï¼ˆå³è½¨è¿¹ï¼‰èšåˆã€‚\n",
    "    è¿”å›: {action_type: {trajectory_id: [items...] } }\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(lambda: defaultdict(list))\n",
    "    for item in data:\n",
    "        tid = item.get('id', '')\n",
    "        act = extract_action_type(tid)\n",
    "        if act:\n",
    "            grouped[act][tid].append(item)\n",
    "    return grouped\n",
    "\n",
    "def dump_jsonl(data, out_path: str):\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "    # 1) åŠ è½½æ•°æ®\n",
    "    data = load_jsonl(INPUT_JSONL)\n",
    "\n",
    "    # 2) æŒ‰ç±»åˆ« & è½¨è¿¹åˆ†ç»„\n",
    "    grouped = group_by_trajectory(data)\n",
    "    print(f\"âœ“ å…±å‘ç° {len(grouped)} ä¸ªç±»åˆ«ï¼ˆåŸºäº extract_action_typeï¼‰\\n\")\n",
    "\n",
    "    # 3) åˆ†å±‚åˆ’åˆ† SFT / RL\n",
    "    sft_data, rl_data = [], []\n",
    "\n",
    "    category_stats = []  # ç”¨äºæ‰“å°ç»Ÿè®¡\n",
    "    for act, traj_map in grouped.items():\n",
    "        traj_ids = list(traj_map.keys())\n",
    "        random.shuffle(traj_ids)\n",
    "\n",
    "        # è®¡ç®— SFT è½¨è¿¹æ•°é‡\n",
    "        sft_count = int(len(traj_ids) * SPLIT_RATIO)\n",
    "        sft_traj = traj_ids[:sft_count]\n",
    "        rl_traj = traj_ids[sft_count:]\n",
    "\n",
    "        # æ”¶é›†æ•°æ®\n",
    "        sft_items = [item for tid in sft_traj for item in traj_map[tid]]\n",
    "        rl_items = [item for tid in rl_traj for item in traj_map[tid]]\n",
    "\n",
    "        sft_data.extend(sft_items)\n",
    "        rl_data.extend(rl_items)\n",
    "\n",
    "        # è®°å½•ç»Ÿè®¡\n",
    "        category_stats.append({\n",
    "            'ç±»åˆ«': act,\n",
    "            'SFT_è½¨è¿¹æ•°': len(sft_traj),\n",
    "            'RL_è½¨è¿¹æ•°': len(rl_traj),\n",
    "            'SFT_æ ·æœ¬æ•°': len(sft_items),\n",
    "            'RL_æ ·æœ¬æ•°': len(rl_items),\n",
    "        })\n",
    "\n",
    "    # 4) å†™å‡ºæ–‡ä»¶\n",
    "    dump_jsonl(sft_data, SFT_JSONL)\n",
    "    dump_jsonl(rl_data, RL_JSONL)\n",
    "\n",
    "    # 5) æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n====== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ======\")\n",
    "    print(f\"æ€»ç±»åˆ«æ•°: {len(category_stats)}\")\n",
    "    print(f\"SFT : RL = {SPLIT_RATIO:.0%} : {1-SPLIT_RATIO:.0%}\\n\")\n",
    "\n",
    "    print(\"ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"{'ç±»åˆ«':25s} | {'SFTè½¨è¿¹':7s} {'RLè½¨è¿¹':7s} {'SFTæ ·æœ¬':7s} {'RLæ ·æœ¬':7s}\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    for stat in category_stats:\n",
    "        print(f\"{stat['ç±»åˆ«']:25s} | \"\n",
    "              f\"{stat['SFT_è½¨è¿¹æ•°']:7d} {stat['RL_è½¨è¿¹æ•°']:7d} \"\n",
    "              f\"{stat['SFT_æ ·æœ¬æ•°']:7d} {stat['RL_æ ·æœ¬æ•°']:7d}\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"SFT æ€»æ ·æœ¬: {len(sft_data)}   RL æ€»æ ·æœ¬: {len(rl_data)}\")\n",
    "    print(f\"ğŸ‘‰ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:\\n   - {SFT_JSONL}\\n   - {RL_JSONL}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cb5572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸåŠ è½½ 5919 æ¡æ•°æ®\n",
      "âœ“ å…±å‘ç° 24 ä¸ªç±»åˆ«ï¼ˆåŸºäº extract_action_typeï¼‰\n",
      "\n",
      "\n",
      "====== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ======\n",
      "æ€»ç±»åˆ«æ•°: 24\n",
      "SFT : RL = 20% : 80%\n",
      "\n",
      "ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\n",
      "------------------------------------------------------------\n",
      "ç±»åˆ«                        | SFTè½¨è¿¹   RLè½¨è¿¹    SFTæ ·æœ¬   RLæ ·æœ¬   \n",
      "------------------------------------------------------------\n",
      "battery_insertion_with_pullout |      11      46      66     262\n",
      "cylinder_pick_box_place_close |      11      47      60     269\n",
      "brick_piled_then_press_thrice |       8      35      44     187\n",
      "pick_shelf_insert_machine_press_switch_place_plate |       7      30      40     178\n",
      "plate_push                |       8      35      27     108\n",
      "place_button              |       9      39      49     187\n",
      "plug_extract_from         |       8      32      44     194\n",
      "plug_pullout_then_press   |       9      38      56     225\n",
      "pour_bread_then_place     |       7      30      43     170\n",
      "place_button_then_press   |      11      44      61     260\n",
      "plug_pullout              |       7      29      44     183\n",
      "seal_stamping             |       9      36      60     230\n",
      "nut_place                 |      10      42      63     276\n",
      "plug_insertion_v2         |       9      37      66     221\n",
      "plug_insertion            |       9      37      55     207\n",
      "gear_place                |      10      42      65     278\n",
      "push_break_pick_shelf_insert_machine_press_switch_place_plate |       5      23      19     101\n",
      "push_bewak_pick_machine_place_plate |       7      32      37     147\n",
      "wipe_panel                |       9      40      41     210\n",
      "throw_battery             |      10      40      64     240\n",
      "throw_battery_twice       |       9      38      64     262\n",
      "tool_liftn_box_place      |       9      38      51     214\n",
      "remove_and_insert_battery |       0       2       0      10\n",
      "switch_manipulation       |       6      27      29     152\n",
      "------------------------------------------------------------\n",
      "SFT æ€»æ ·æœ¬: 1148   RL æ€»æ ·æœ¬: 4771\n",
      "ğŸ‘‰ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:\n",
      "   - /home/vcj9002/jianshu/workspace/code/ProgressLM/data/train/text_demo/text_h5_tienkung_xsens_sft.jsonl\n",
      "   - /home/vcj9002/jianshu/workspace/code/ProgressLM/data/train/text_demo/text_h5_tienkung_xsens_rl.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===================== é…ç½®åŒº =====================\n",
    "INPUT_JSONL = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/raw/text_demo/h5_tienkung_xsens_text_all.jsonl'\n",
    "OUTPUT_DIR  = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/train/text_demo'\n",
    "SFT_JSONL   = os.path.join(OUTPUT_DIR, 'text_h5_tienkung_xsens_sft.jsonl')\n",
    "RL_JSONL    = os.path.join(OUTPUT_DIR, 'text_h5_tienkung_xsens_rl.jsonl')\n",
    "SPLIT_RATIO = 0.2   # SFT å  20%ï¼ŒRL å  80%\n",
    "SEED = 42\n",
    "# =================================================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def extract_action_type(id_string: str):\n",
    "    parts = id_string.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def load_jsonl(jsonl_path: str):\n",
    "    data = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®\")\n",
    "    return data\n",
    "\n",
    "def group_by_trajectory(data):\n",
    "    \"\"\"\n",
    "    å°†æ•°æ®æŒ‰å®Œæ•´ idï¼ˆå³è½¨è¿¹ï¼‰èšåˆã€‚\n",
    "    è¿”å›: {action_type: {trajectory_id: [items...] } }\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(lambda: defaultdict(list))\n",
    "    for item in data:\n",
    "        tid = item.get('id', '')\n",
    "        act = extract_action_type(tid)\n",
    "        if act:\n",
    "            grouped[act][tid].append(item)\n",
    "    return grouped\n",
    "\n",
    "def dump_jsonl(data, out_path: str):\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "    # 1) åŠ è½½æ•°æ®\n",
    "    data = load_jsonl(INPUT_JSONL)\n",
    "\n",
    "    # 2) æŒ‰ç±»åˆ« & è½¨è¿¹åˆ†ç»„\n",
    "    grouped = group_by_trajectory(data)\n",
    "    print(f\"âœ“ å…±å‘ç° {len(grouped)} ä¸ªç±»åˆ«ï¼ˆåŸºäº extract_action_typeï¼‰\\n\")\n",
    "\n",
    "    # 3) åˆ†å±‚åˆ’åˆ† SFT / RL\n",
    "    sft_data, rl_data = [], []\n",
    "\n",
    "    category_stats = []  # ç”¨äºæ‰“å°ç»Ÿè®¡\n",
    "    for act, traj_map in grouped.items():\n",
    "        traj_ids = list(traj_map.keys())\n",
    "        random.shuffle(traj_ids)\n",
    "\n",
    "        # è®¡ç®— SFT è½¨è¿¹æ•°é‡\n",
    "        sft_count = int(len(traj_ids) * SPLIT_RATIO)\n",
    "        sft_traj = traj_ids[:sft_count]\n",
    "        rl_traj = traj_ids[sft_count:]\n",
    "\n",
    "        # æ”¶é›†æ•°æ®\n",
    "        sft_items = [item for tid in sft_traj for item in traj_map[tid]]\n",
    "        rl_items = [item for tid in rl_traj for item in traj_map[tid]]\n",
    "\n",
    "        sft_data.extend(sft_items)\n",
    "        rl_data.extend(rl_items)\n",
    "\n",
    "        # è®°å½•ç»Ÿè®¡\n",
    "        category_stats.append({\n",
    "            'ç±»åˆ«': act,\n",
    "            'SFT_è½¨è¿¹æ•°': len(sft_traj),\n",
    "            'RL_è½¨è¿¹æ•°': len(rl_traj),\n",
    "            'SFT_æ ·æœ¬æ•°': len(sft_items),\n",
    "            'RL_æ ·æœ¬æ•°': len(rl_items),\n",
    "        })\n",
    "\n",
    "    # 4) å†™å‡ºæ–‡ä»¶\n",
    "    dump_jsonl(sft_data, SFT_JSONL)\n",
    "    dump_jsonl(rl_data, RL_JSONL)\n",
    "\n",
    "    # 5) æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n====== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ======\")\n",
    "    print(f\"æ€»ç±»åˆ«æ•°: {len(category_stats)}\")\n",
    "    print(f\"SFT : RL = {SPLIT_RATIO:.0%} : {1-SPLIT_RATIO:.0%}\\n\")\n",
    "\n",
    "    print(\"ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"{'ç±»åˆ«':25s} | {'SFTè½¨è¿¹':7s} {'RLè½¨è¿¹':7s} {'SFTæ ·æœ¬':7s} {'RLæ ·æœ¬':7s}\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    for stat in category_stats:\n",
    "        print(f\"{stat['ç±»åˆ«']:25s} | \"\n",
    "              f\"{stat['SFT_è½¨è¿¹æ•°']:7d} {stat['RL_è½¨è¿¹æ•°']:7d} \"\n",
    "              f\"{stat['SFT_æ ·æœ¬æ•°']:7d} {stat['RL_æ ·æœ¬æ•°']:7d}\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"SFT æ€»æ ·æœ¬: {len(sft_data)}   RL æ€»æ ·æœ¬: {len(rl_data)}\")\n",
    "    print(f\"ğŸ‘‰ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:\\n   - {SFT_JSONL}\\n   - {RL_JSONL}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸåŠ è½½ 4376 æ¡æ•°æ®\n",
      "âœ“ å·²å†™å‡º Train: 3436 æ¡ -> /Users/cxqian/Codes/ProgressLM/data/eval/text/text_h5_tienkung_xsens_rl\n",
      "âœ“ å·²å†™å‡º Test : 940 æ¡ -> /Users/cxqian/Codes/ProgressLM/data/eval/text/text_h5_tienkung_xsens_test\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Train ç»Ÿè®¡\n",
      "============================================================\n",
      "  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: 18\n",
      "  â€¢ Trajectoryæ€»æ•°: 608\n",
      "  â€¢ æ ·æœ¬æ€»æ•°: 3436\n",
      "\n",
      "è¯¦ç»†ç»Ÿè®¡ï¼š\n",
      "                                                         åŠ¨ä½œç±»å‹  Trajectoryæ•°é‡  æ ·æœ¬æ•°é‡\n",
      "                                                   gear_place            40   263\n",
      "                                cylinder_pick_box_place_close            45   258\n",
      "                                                    nut_place            38   254\n",
      "                                      place_button_then_press            38   233\n",
      "                                                throw_battery            39   233\n",
      "                               battery_insertion_with_pullout            38   215\n",
      "                                                seal_stamping            33   208\n",
      "                                                   wipe_panel            39   206\n",
      "                                            plug_insertion_v2            33   194\n",
      "                                         tool_liftn_box_place            33   192\n",
      "                                               plug_insertion            31   178\n",
      "                                            plug_extract_from            29   177\n",
      "                                                 place_button            36   175\n",
      "                                                 plug_pullout            26   162\n",
      "           pick_shelf_insert_machine_press_switch_place_plate            26   155\n",
      "                          push_bewak_pick_machine_place_plate            30   138\n",
      "                                                   plate_push            33   102\n",
      "push_break_pick_shelf_insert_machine_press_switch_place_plate            21    93\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Test ç»Ÿè®¡\n",
      "============================================================\n",
      "  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: 5\n",
      "  â€¢ Trajectoryæ€»æ•°: 158\n",
      "  â€¢ æ ·æœ¬æ€»æ•°: 940\n",
      "\n",
      "è¯¦ç»†ç»Ÿè®¡ï¼š\n",
      "                         åŠ¨ä½œç±»å‹  Trajectoryæ•°é‡  æ ·æœ¬æ•°é‡\n",
      "          throw_battery_twice            36   250\n",
      "      plug_pullout_then_press            37   220\n",
      "brick_piled_then_press_thrice            33   177\n",
      "        pour_bread_then_place            29   165\n",
      "          switch_manipulation            23   128\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ æ•´ä½“å æ¯”ï¼ˆæŒ‰æ ·æœ¬/trajectory/ç±»åˆ«æ•°ï¼‰\n",
      "  â€¢ Test æ ·æœ¬å æ¯”: 940/4376 = 21.48%\n",
      "  â€¢ Test Trajectoryå æ¯”: 158/766 = 20.63%\n",
      "  â€¢ Test ç±»åˆ«å æ¯”: 5/23 = 21.74%\n",
      "\n",
      "âœ… åˆ‡åˆ†å®Œæˆã€‚ç±»åˆ«äº’æ–¥ï¼šTest = 5 ç±»ï¼›Train = å…¶ä½™å…¨éƒ¨ç±»åˆ«ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===================== é…ç½®åŒº =====================\n",
    "# è¾“å…¥ä¸è¾“å‡º\n",
    "INPUT_JSONL = '/Users/cxqian/Codes/ProgressLM/data/train/text_demo/text_h5_tienkung_xsens_sft.jsonl'  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„\n",
    "OUTPUT_DIR  = '/Users/cxqian/Codes/ProgressLM/data/eval/text'  # è¾“å‡ºç›®å½•ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºï¼‰\n",
    "TRAIN_JSONL = os.path.join(OUTPUT_DIR, 'text_h5_tienkung_xsens_sft')\n",
    "TEST_JSONL  = os.path.join(OUTPUT_DIR, 'text_h5_tienkung_xsens_test2')\n",
    "\n",
    "# å›ºå®šæµ‹è¯•é›† 5 ä¸ªç±»åˆ«ï¼ˆå…¶ä½™å…¨éƒ¨ä½œä¸ºè®­ç»ƒï¼‰\n",
    "TEST_CLASSES = {\n",
    "    'brick_piled_then_press_thrice',\n",
    "    'plug_pullout_then_press',\n",
    "    'switch_manipulation',\n",
    "    'pour_bread_then_place',\n",
    "    'throw_battery_twice',\n",
    "}\n",
    "# =================================================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def extract_action_type(id_string: str):\n",
    "    \"\"\"\n",
    "    ä»IDä¸­æå–åŠ¨ä½œç±»å‹\n",
    "    çº¦å®š: æ ¼å¼ä¸º æ•°æ®é›†åç§°/åŠ¨ä½œç±»å‹/æ—¶é—´æˆ³ æˆ–ç›¸ä¼¼ï¼ˆè‡³å°‘åŒ…å«ä¸¤æ®µï¼‰\n",
    "    \"\"\"\n",
    "    parts = id_string.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def load_jsonl(jsonl_path: str):\n",
    "    data = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®\")\n",
    "    return data\n",
    "\n",
    "def split_by_classes(data, test_classes: set):\n",
    "    \"\"\"æ ¹æ®ç±»åˆ«é›†åˆåˆ’åˆ† train/testï¼ˆç±»åˆ«äº’æ–¥ï¼‰\"\"\"\n",
    "    train, test = [], []\n",
    "    for item in data:\n",
    "        act = extract_action_type(item.get('id', ''))\n",
    "        if act in test_classes:\n",
    "            test.append(item)\n",
    "        else:\n",
    "            train.append(item)\n",
    "    return train, test\n",
    "\n",
    "def dump_jsonl(data, out_path: str):\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def summarize_split(data, title: str):\n",
    "    \"\"\"è¾“å‡ºè¯¥ split å†…çš„åŸºç¡€ç»Ÿè®¡ï¼ˆæ ·æœ¬/trajectory/æŒ‰ç±»åˆ«åˆ†å¸ƒï¼‰\"\"\"\n",
    "    # ç»Ÿè®¡\n",
    "    action_data = defaultdict(lambda: {'trajectories': set(), 'samples': 0})\n",
    "    for item in data:\n",
    "        id_string = item.get('id', '')\n",
    "        action_type = extract_action_type(id_string)\n",
    "        if action_type:\n",
    "            # æŒ‰ä½ çš„åŸå§‹é€»è¾‘ï¼šä»¥å®Œæ•´ id ä½œä¸º trajectory å”¯ä¸€æ ‡è¯†\n",
    "            action_data[action_type]['trajectories'].add(id_string)\n",
    "            action_data[action_type]['samples'] += 1\n",
    "\n",
    "    # è½¬ DataFrame\n",
    "    rows = []\n",
    "    for act, info in action_data.items():\n",
    "        rows.append({\n",
    "            'åŠ¨ä½œç±»å‹': act,\n",
    "            'Trajectoryæ•°é‡': len(info['trajectories']),\n",
    "            'æ ·æœ¬æ•°é‡': info['samples']\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values('æ ·æœ¬æ•°é‡', ascending=False)\n",
    "\n",
    "    # æ±‡æ€»\n",
    "    n_actions = len(df)\n",
    "    n_traj = int(df['Trajectoryæ•°é‡'].sum()) if not df.empty else 0\n",
    "    n_samples = int(df['æ ·æœ¬æ•°é‡'].sum()) if not df.empty else 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ“Š {title} ç»Ÿè®¡\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  â€¢ åŠ¨ä½œç±»å‹æ•°é‡: {n_actions}\")\n",
    "    print(f\"  â€¢ Trajectoryæ€»æ•°: {n_traj}\")\n",
    "    print(f\"  â€¢ æ ·æœ¬æ€»æ•°: {n_samples}\")\n",
    "    if not df.empty:\n",
    "        print(\"\\nè¯¦ç»†ç»Ÿè®¡ï¼š\")\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nè¯¥ split ä¸ºç©ºã€‚\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    return {\n",
    "        'n_actions': n_actions,\n",
    "        'n_traj': n_traj,\n",
    "        'n_samples': n_samples,\n",
    "        'df': df\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "\n",
    "    # 1) è¯»å…¥\n",
    "    data = load_jsonl(INPUT_JSONL)\n",
    "\n",
    "    # 2) åˆ‡åˆ†ï¼ˆç±»åˆ«äº’æ–¥ï¼‰\n",
    "    train, test = split_by_classes(data, TEST_CLASSES)\n",
    "\n",
    "    # 3) å†™å‡º\n",
    "    dump_jsonl(train, TRAIN_JSONL)\n",
    "    dump_jsonl(test, TEST_JSONL)\n",
    "    print(f\"âœ“ å·²å†™å‡º Train: {len(train)} æ¡ -> {TRAIN_JSONL}\")\n",
    "    print(f\"âœ“ å·²å†™å‡º Test : {len(test)} æ¡ -> {TEST_JSONL}\")\n",
    "\n",
    "    # 4) ç»Ÿè®¡ï¼ˆåˆ†åˆ«å¯¹ Train/Testï¼‰\n",
    "    train_stat = summarize_split(train, \"Train\")\n",
    "    test_stat  = summarize_split(test,  \"Test\")\n",
    "\n",
    "    # 5) æ±‡æ€»æ¯”ä¾‹ï¼ˆä¾¿äºå¿«é€Ÿ sanity checkï¼‰\n",
    "    total_samples = train_stat['n_samples'] + test_stat['n_samples']\n",
    "    total_traj    = train_stat['n_traj'] + test_stat['n_traj']\n",
    "    total_actions = train_stat['n_actions'] + test_stat['n_actions']  # åº”ä¸ºå…¨ä½“ç±»åˆ«æ•°é‡\n",
    "\n",
    "    print(\"ğŸ“Œ æ•´ä½“å æ¯”ï¼ˆæŒ‰æ ·æœ¬/trajectory/ç±»åˆ«æ•°ï¼‰\")\n",
    "    if total_samples > 0:\n",
    "        print(f\"  â€¢ Test æ ·æœ¬å æ¯”: {test_stat['n_samples']}/{total_samples} = {test_stat['n_samples']/total_samples:.2%}\")\n",
    "    if total_traj > 0:\n",
    "        print(f\"  â€¢ Test Trajectoryå æ¯”: {test_stat['n_traj']}/{total_traj} = {test_stat['n_traj']/total_traj:.2%}\")\n",
    "    if total_actions > 0:\n",
    "        print(f\"  â€¢ Test ç±»åˆ«å æ¯”: {test_stat['n_actions']}/{total_actions} = {test_stat['n_actions']/total_actions:.2%}\")\n",
    "\n",
    "    print(\"\\nâœ… åˆ‡åˆ†å®Œæˆã€‚ç±»åˆ«äº’æ–¥ï¼šTest = 5 ç±»ï¼›Train = å…¶ä½™å…¨éƒ¨ç±»åˆ«ã€‚\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
