{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf69a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成！共生成 15056 条记录\n",
      "输出文件：/home/vcj9002/jianshu/workspace/data/COCO/annotations/raw/text/h5_franka_3rgb_text_all.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_dataset(input_file, output_file):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为新格式\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入的JSON文件路径\n",
    "        output_file: 输出的JSONL文件路径\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    converted_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        original_id = item['id']\n",
    "        response = item['response']\n",
    "        \n",
    "        # 1. 处理id：删除 /success_episodes/train/ 和 /data\n",
    "        new_id = original_id.replace('/success_episodes/train/', '/')\n",
    "        new_id = new_id.replace('/data', '')\n",
    "        \n",
    "        # 2. 获取task_goal\n",
    "        task_goal = response['task_summary']\n",
    "        \n",
    "        # 3. 获取所有step_description作为text_demo\n",
    "        text_demo = [step['step_description'] for step in response['steps']]\n",
    "        \n",
    "        # 4. 计算total_steps\n",
    "        total_steps = len(response['steps'])\n",
    "        \n",
    "        # 5. 获取data_source（第一个/之前的内容）\n",
    "        data_source = new_id.split('/')[0]\n",
    "        \n",
    "        # 6. 为每个step生成一条记录\n",
    "        for idx, step in enumerate(response['steps']):\n",
    "            # closest_idx是当前step的索引（从1开始）\n",
    "            closest_idx = idx + 1\n",
    "            \n",
    "            # progress_score是完成该step后的进度百分比（字符串格式）\n",
    "            progress_score = f\"{int(((idx + 1) / total_steps) * 100)}%\"\n",
    "            \n",
    "            # stage_to_estimate是该step的end_frame\n",
    "            stage_to_estimate = step['end_frame']\n",
    "            \n",
    "            converted_item = {\n",
    "                \"id\": new_id,\n",
    "                \"task_goal\": task_goal,\n",
    "                \"text_demo\": text_demo,\n",
    "                \"total_steps\": total_steps,\n",
    "                \"stage_to_estimate\": stage_to_estimate,\n",
    "                \"closest_idx\": closest_idx,\n",
    "                \"progress_score\": progress_score,\n",
    "                \"data_source\": data_source\n",
    "            }\n",
    "            \n",
    "            converted_data.append(converted_item)\n",
    "    \n",
    "    # 写入JSONL文件（每行一个JSON对象）\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in converted_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"转换完成！共生成 {len(converted_data)} 条记录\")\n",
    "    print(f\"输出文件：{output_file}\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "# if __name__ == \"__main__\":\n",
    "#     input_file = \"/home/vcj9002/jianshu/workspace/data/robomind/data/annotations/language_description_annotation_json/h5_tienkung_xsens.json\"\n",
    "#     output_file = \"/home/vcj9002/jianshu/workspace/data/COCO/annotations/raw/text/h5_tienkung_xsens_text_all.jsonl\"\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     input_file = \"/home/vcj9002/jianshu/workspace/data/robomind/data/annotations/language_description_annotation_json/h5_ur_1rgb.json\"\n",
    "#     output_file = \"/home/vcj9002/jianshu/workspace/data/COCO/annotations/raw/text/h5_ur_1rgb_text_all.jsonl\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/home/vcj9002/jianshu/workspace/data/robomind/data/annotations/language_description_annotation_json/h5_franka_3rgb.json\"\n",
    "    output_file = \"/home/vcj9002/jianshu/workspace/data/COCO/annotations/raw/text/h5_franka_3rgb_text_all.jsonl\"\n",
    "\n",
    "    convert_dataset(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d58413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_dataset(input_file, output_file):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为新格式\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入的JSON文件路径\n",
    "        output_file: 输出的JSONL文件路径\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    converted_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        original_id = item['id']\n",
    "        response = item['response']\n",
    "        \n",
    "        # 1. 处理id：删除 /success_episodes/train/ 和 /data\n",
    "        new_id = original_id.replace('/success_episodes/train/', '/')\n",
    "        new_id = new_id.replace('/data', '')\n",
    "        \n",
    "        # 2. 获取task_goal\n",
    "        task_goal = response['task_summary']\n",
    "        \n",
    "        # 3. 获取所有step_description作为text_demo\n",
    "        text_demo = [step['step_description'] for step in response['steps']]\n",
    "        \n",
    "        # 4. 计算total_steps（忽略最后一个step）\n",
    "        total_steps = len(response['steps']) - 1\n",
    "        \n",
    "        # 5. 获取data_source（第一个/之前的内容）\n",
    "        data_source = new_id.split('/')[0]\n",
    "        \n",
    "        # 6. 为每个step生成一条记录（忽略最后一个step）\n",
    "        for idx, step in enumerate(response['steps'][:-1]):\n",
    "            # closest_idx是当前step的索引（从1开始）\n",
    "            closest_idx = idx + 1\n",
    "            \n",
    "            # progress_score是完成该step后的进度百分比（字符串格式）\n",
    "            progress_score = f\"{int(((idx + 1) / total_steps) * 100)}%\"\n",
    "            \n",
    "            # stage_to_estimate是该step的end_frame\n",
    "            stage_to_estimate = step['end_frame']\n",
    "            \n",
    "            converted_item = {\n",
    "                \"id\": new_id,\n",
    "                \"task_goal\": task_goal,\n",
    "                \"text_demo\": text_demo,\n",
    "                \"total_steps\": total_steps,\n",
    "                \"stage_to_estimate\": stage_to_estimate,\n",
    "                \"closest_idx\": closest_idx,\n",
    "                \"progress_score\": progress_score,\n",
    "                \"data_source\": data_source\n",
    "            }\n",
    "            \n",
    "            converted_data.append(converted_item)\n",
    "    \n",
    "    # 写入JSONL文件（每行一个JSON对象）\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in converted_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"转换完成！共生成 {len(converted_data)} 条记录\")\n",
    "    print(f\"输出文件：{output_file}\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/home/vcj9002/jianshu/workspace/data/robomind/data/annotations/language_description_annotation_json/h5_agilex_3rgb.json\"\n",
    "    output_file = \"/home/vcj9002/jianshu/workspace/data/COCO/annotations/raw/text/h5_agilex_3rgb_text.jsonl\"\n",
    "    \n",
    "    convert_dataset(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
