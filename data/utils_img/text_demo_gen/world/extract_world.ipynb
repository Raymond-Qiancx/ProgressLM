{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ca313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！共生成 12114 条记录\n",
      "涉及 1593 个不同的source_id\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_jsonl(input_file, output_file):\n",
    "    \"\"\"\n",
    "    处理JSONL文件，按source_id分组并转换为新格式\n",
    "    \n",
    "    参数:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        output_file: 输出JSONL文件路径\n",
    "    \"\"\"\n",
    "    # 读取所有数据并按source_id分组\n",
    "    grouped_data = defaultdict(list)\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data = json.loads(line)\n",
    "                grouped_data[data['source_id']].append(data)\n",
    "    \n",
    "    # 处理每个source_id的数据\n",
    "    results = []\n",
    "    \n",
    "    for source_id, items in grouped_data.items():\n",
    "        # 按step排序\n",
    "        items.sort(key=lambda x: int(x['step']))\n",
    "        \n",
    "        # 获取基本信息\n",
    "        total_steps = len(items)\n",
    "        task_goal = items[0]['task_goal']\n",
    "        data_source = items[0]['data_source']\n",
    "        \n",
    "        # 收集所有action\n",
    "        text_demo = [item['action'] for item in items]\n",
    "        \n",
    "        # 为每个step生成一条记录\n",
    "        for item in items:\n",
    "            step = int(item['step'])\n",
    "            \n",
    "            # 处理end_img，保留最后一个斜杠后的内容\n",
    "            end_img = item['end_img']\n",
    "            stage_to_estimate = end_img.split('/')[-1]\n",
    "            \n",
    "            # 计算progress_score (整数百分比，带百分号)\n",
    "            progress_score = f\"{int((step / total_steps) * 100)}%\"\n",
    "            \n",
    "            # 构建输出记录\n",
    "            output_record = {\n",
    "                \"id\": f\"{data_source}/{source_id}\",\n",
    "                \"task_goal\": task_goal,\n",
    "                \"text_demo\": text_demo,\n",
    "                \"total_steps\": str(total_steps),\n",
    "                \"stage_to_estimate\": stage_to_estimate,\n",
    "                \"closest_idx\": str(step),\n",
    "                \"progress_score\": str(progress_score),\n",
    "                \"data_source\": data_source\n",
    "            }\n",
    "            \n",
    "            results.append(output_record)\n",
    "    \n",
    "    # 写入输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for record in results:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"处理完成！共生成 {len(results)} 条记录\")\n",
    "    print(f\"涉及 {len(grouped_data)} 个不同的source_id\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 实际使用时调用这个函数\n",
    "    # process_jsonl('/home/vcj9002/jianshu/workspace/data/worldvlm/annotations/coin.jsonl', '/home/vcj9002/jianshu/workspace/data/robomind/codes/text_demo/coin_text.jsonl')\n",
    "    process_jsonl('/home/vcj9002/jianshu/workspace/data/worldvlm/annotations/crosstask.jsonl', '/home/vcj9002/jianshu/workspace/data/robomind/codes/text_demo/crosstask_text.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
